# -*- coding: utf-8 -*-
"""part2_encoder_from_part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mE66lY1aULebVK3Ok4ZkAiiwDjBqTFRG
"""

import os
import numpy as np
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from sklearn.manifold import TSNE
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

#miscelaneous
from google.colab import files

# Download pre-trained weights from part 1 (attempt 8)
!gdown 12LQ-GVdlMLDK-xmZSkTrtfgVCnEV2AQt

# Download dataset 2 and 3 (prostate cancer and animal faces)
if not os.path.exists("Dataset_2.zip"):
  !gdown 1cv4i5bSuGUgxGam73D_JnAN2G4XtSFWf
  !unzip Dataset_2.zip
else:
  print("The dataset 2 has already been downloaded. Skipping this step.")

if not os.path.exists("Dataset_3.zip"):
  !gdown 1flt1M8ME-5oKoZ5M3etK3Zal67FVxSJo
  !unzip Dataset_3.zip
else:
  print("The dataset 3 has already been downloaded. Skipping this step.")

#preparing and loading the images in the dataset
def loadImagesForPreTrained(path, batch_size):
  #firstly defining the transformations used on the images
  transformation = transforms.Compose([
      transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
      transforms.ToTensor(),
      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
  ])

  #now loading the images
  data_set = datasets.ImageFolder(path, transform=transformation)

  #creating dataloader
  data_loader = DataLoader(data_set, batch_size=batch_size, shuffle=False)

  return data_loader

prostate_cancer_loader= loadImagesForPreTrained("Prostate Cancer", 64)
animal_faces_loader= loadImagesForPreTrained("Animal Faces", 64)

# Setup trained model from Task 1
model = models.resnet34()
num_features = model.fc.in_features
model.fc = nn.Identity()
checkpoint = torch.load("attempt8.tar", weights_only=True)
print(checkpoint.keys())
# load the weights
model.load_state_dict(checkpoint['model_state_dict'], strict=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

def extract_features_for_tsne(model, data_loader, device):

    model.eval()  # Set model to evaluation mode
    features, labels = [], []
    # Remove the classification layer (last layer) to get only feature outputs
    with torch.no_grad():
        for images, target_labels in data_loader:
            images = images.to(device)

            # Remove the final layer for feature extraction (assuming model_features is the model without the last layer)
            outputs = model(images)  # Replace model with model_features if the last layer was sliced
            features.append(outputs.view(outputs.size(0), -1).cpu().numpy())  # Flatten feature tensor
            labels.extend(target_labels.cpu().numpy())  # Collect labels on CPU for t-SNE

    # Concatenate all features for t-SNE processing
    features = np.concatenate(features, axis=0)

    return features, labels

features_prostate_cancer, labels_prostate_cancer = extract_features_for_tsne(model, prostate_cancer_loader, device)
features_animal_faces, labels_animal_faces = extract_features_for_tsne(model, animal_faces_loader, device)

def plot_tsne(features, labels, dataset_name, label_mapping):
  # Apply t-SNE
  tsne = TSNE(n_components=2, random_state=42)
  reduced_features = tsne.fit_transform(features)

  unique_classes = np.unique(labels)
  num_classes = len(unique_classes)

  plt.figure(figsize=(10, 6))
  colors = plt.cm.get_cmap('viridis', num_classes)
  # colors = plt.colormaps['viridis'](num_classes)

  for class_index in unique_classes:
    indices = np.where(labels == class_index)
    class_name = label_mapping.get(class_index, f"Class {class_index}")
    plt.scatter(
      reduced_features[indices, 0],
      reduced_features[indices, 1],
      label= class_name,
      c=[colors(class_index)],
      alpha=0.7,
    )

  plt.title(f"t-SNE Visualization of CNN Extracted Features - {dataset_name}")
  plt.xlabel("t-SNE Feature 1")
  plt.ylabel("t-SNE Feature 2")
  plt.legend(loc='best')
  plt.show()

# Plotting for Prostate Cancer dataset
plot_tsne(features_prostate_cancer, labels_prostate_cancer, dataset_name = "Prostate Cancer", label_mapping = {0: 'gland', 1: 'nongland', 2: 'tumor'})

# Plotting for Animal Faces dataset
plot_tsne(features_animal_faces, labels_animal_faces, dataset_name="Animal Faces", label_mapping = {0: 'cat', 1: 'dog', 2: 'wild'})

# Classification of extracted features for prostate cancer
X_train, X_test, y_train, y_test = train_test_split(features_prostate_cancer, labels_prostate_cancer, test_size=0.3, random_state=42)

# Train a Logistic Regression model
lr = LogisticRegression(penalty=None)
lr.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lr.predict(X_test)

# Evaluate the classifier
print("For prostate cancer dataset using logistic regression:")
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

classes=['gland', 'nongland', 'tumor']

ConfusionMatrixDisplay.from_predictions(
    y_test,
    y_pred,
    display_labels=classes,
    cmap='viridis',
    xticks_rotation='vertical'
)

# Classification of extracted features for animal faces
X_train, X_test, y_train, y_test = train_test_split(features_animal_faces, labels_animal_faces, test_size=0.3, random_state=42)

# Create an SVM classifier
svm = SVC(kernel='linear')

# Train the SVM classifier
svm.fit(X_train, y_train)

# Make predictions on the test set
y_pred = svm.predict(X_test)

# Evaluate the classifier
print("For animal faces dataset using SVM:")
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
print("Classification Report:")
print(classification_report(y_test, y_pred))

classes=['cat', 'dog', 'wild']

ConfusionMatrixDisplay.from_predictions(
    y_test,
    y_pred,
    display_labels=classes,
    cmap='viridis',
    xticks_rotation='vertical'
)